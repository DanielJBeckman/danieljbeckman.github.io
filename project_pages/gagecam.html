<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Gage-Cam • Project Overview</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" />
  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      background-color: #f8f9fa;
      color: #212529;
    }

    .hero {
      background-color: #e9ecef;
      padding: 4rem 2rem;
      text-align: center;
    }

    .hero h1 {
      font-size: 2.5rem;
      font-weight: 700;
    }

    .hero p {
      font-size: 1.1rem;
      max-width: 720px;
      margin: 1rem auto 0;
      color: #555;
    }

    .section {
      padding: 3rem 2rem;
      max-width: 960px;
      margin: 0 auto;
    }

    .project-block {
      margin-bottom: 5rem;
    }

    .project-img {
      max-height: 300px;
      width: auto;
      height: auto;
      border-radius: 0.5rem;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .text-block h3 {
      font-size: 1.5rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
    }

    .text-block p {
      font-size: 1rem;
      color: #555;
    }

    footer {
      padding: 2rem 1rem;
    }
  </style>
</head>
<body>

  <!-- Hero Section -->
  <section class="hero">
    <h1>Gage-Cam</h1>
    <p>AI-enabled river stage detection from staff plates using embedded systems and deep learning in the field.</p>
  </section>

  <!-- Staggered Content -->
  <section class="section">
    
    <!-- Block 1 -->
    <div class="row project-block align-items-center">
      <div class="col-md-6">
        <img src="/project_assets/Gagecam1.jpg" alt="Gage-Cam staff plate detection" class="project-img">
      </div>
      <div class="col-md-6">
        <div class="text-block">
          <h3>Overview</h3>
          <p>Gage-Cam is a lightweight embedded vision system designed to detect staff plates and measure river stage using real-time computer vision. Built from Raspberry Pi hardware, it runs a U-Net model trained to identify the physical contour of staff plates and determine the waterline intersection point, enabling in-field elevation measurement without human reading.</p>
        </div>
      </div>
    </div>

    <!-- Block 2 -->
    <div class="row project-block align-items-center flex-md-row-reverse">
      <div class="col-md-6">
        <img src="/project_assets/Gagecam2.png" alt="Field deployment of Gage-Cam" class="project-img">
      </div>
      <div class="col-md-6">
        <div class="text-block">
          <h3>Edge AI in Harsh Conditions</h3>
          <p>Gage-Cam was trained using TensorFlow and Keras on a synthetic data pipeline capable of generating thousands of randomized scenes. With as few as 30 annotated images of a given object, the model could learn to identify that object’s mask in varied environments. The synthetic training data included a wide range of object orientations, lighting conditions, and backgrounds, enabling the U-Net to generalize across staff plate types and real-world complexity — critical for reliable performance in the field.</p>
        </div>
      </div>
    </div>

    <!-- Block 3 -->
    <div class="row project-block align-items-center">
      <div class="col-md-6">
        <img src="/project_assets/Gagecam3.png" alt="Annotated staff plate segmentation" class="project-img">
      </div>
      <div class="col-md-6">
        <div class="text-block">
          <h3>Model Training and Segmentation</h3>
          <p>Gage-Cam uses a U-Net architecture selected for its ability to generate precise, low-artifact segmentation masks in uncontrolled field conditions. As the model downsamples input images, it gains higher-level semantic understanding while progressively losing spatial detail. To preserve accuracy, U-Net employs skip connections that reintroduce high-resolution features from earlier layers into the upsampling path. This design allows the model to maintain sharp object boundaries while still benefiting from deep contextual reasoning — ideal for detecting staff plate geometry in complex natural environments.</p>
        </div>
      </div>
    </div>

    <!-- Add up to 4 more blocks -->
    <div class="row project-block align-items-center flex-md-row-reverse">
      <div class="col-md-6">
        <img src="/project_assets/Gagecam5.jpg" alt="Example image or visualization" class="project-img">
      </div>
      <div class="col-md-6">
        <div class="text-block">
          <h3>Installation & Form Factor</h3>
          <p>Gage-Cam was deployed for a three-day trial on the Neversink River at Godeffroy, NY, during a period of historically low flow. Operating entirely on battery power, the system remained fully self-sufficient throughout the test. Despite difficult lighting and variable flow conditions, the model consistently detected staff plates with high confidence. The trial demonstrated Gage-Cam’s ability to perform reliably in real-world river environments without external power or connectivity.</p>
        </div>
      </div>
    </div>

    <!-- GitHub CTA -->
    <div class="text-center">
      <a href="https://github.com/USGS-NYWSC-HAIL/gage-cam" target="_blank" class="btn btn-outline-primary mt-4">View on GitHub</a>
    </div>

  </section>

  <!-- Footer -->
  <footer class="text-center text-muted">
    <p class="mb-1">&copy; 2025 Daniel Beckman</p>
    <a href="/" class="text-decoration-none small text-primary">← Return to Home</a>
  </footer>

</body>
</html>